name: Data Scraping Automation

on:
  workflow_dispatch:
  # schedule:
  #   - cron: '0 9 * * 1'

jobs:
  scrape-data:
    runs-on: ubuntu-latest
    timeout-minutes: 480

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Install your dependencies
        pip install -r requirements.txt
        # Ensure Playwright and browsers are installed
        pip install playwright
        playwright install --with-deps

    - name: Verify input files
      run: |
        if [ ! -f "urls with titles.csv" ]; then
          echo "Error: urls with titles.csv not found"
          exit 1
        fi
        echo "Input file found, starting scraper..."

    - name: Run scraper
      env:
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        YOUR_SITE_URL: ${{ secrets.YOUR_SITE_URL }}
        YOUR_SITE_NAME: ${{ secrets.YOUR_SITE_NAME }}
      run: |
        python main.py

    - name: Check output files
      run: |
        if [ -f "pricing_results_with_resume.json" ]; then
          echo "✅ Main results file created"
          wc -l "pricing_results_with_resume.json"
        else
          echo "❌ Main results file not found"
        fi
        
        if [ -f "pricing_results_with_resume_checkpoint.json" ]; then
          echo "✅ Checkpoint file found"
        else
          echo "ℹ️ No checkpoint file (normal if completed)"
        fi
  
    - name: Upload results as artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: scraping-results-${{ github.run_number }}
        path: |
          pricing_results_with_resume.json
          pricing_results_with_resume_checkpoint.json
        retention-days: 30

    - name: Commit and push results
      if: success()
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -A
        if ! git diff --cached --quiet; then
          git commit -m "Update scraping results - $(date '+%Y-%m-%d %H:%M:%S UTC')"
          git push
        else
          echo "No changes to commit"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}